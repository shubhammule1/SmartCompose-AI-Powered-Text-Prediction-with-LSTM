{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pgt2bbFUr2gZ"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Data plays a vital role in our everyday life.\n",
        "Directly or indirectly, for daily life decisions, we depend on some data, be it choosing a novel to read from a list of books, buying a thing after considering the budget, and so on.\n",
        "Have you ever imagined searching for something on Google or Yahoo generates a lot of data?\n",
        "This data is essential to analyze user experiences.\n",
        "Getting recommendations on various e-commerce websites after buying a product and tracking parcels during delivery are part of Data Analytics which involves analyzing the raw data to make informed decisions.\n",
        "But this raw data does not help make decisions if it has some redundancy, inconsistency, or inaccuracy.\n",
        "Therefore, this data needs to be cleaned before considering for analysis.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "jCcmBCp_sQ5U",
        "outputId": "98831f64-81c3-40a0-9130-d89e6862a0fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Data plays a vital role in our everyday life.\\nDirectly or indirectly, for daily life decisions, we depend on some data, be it choosing a novel to read from a list of books, buying a thing after considering the budget, and so on.\\nHave you ever imagined searching for something on Google or Yahoo generates a lot of data?\\nThis data is essential to analyze user experiences.\\nGetting recommendations on various e-commerce websites after buying a product and tracking parcels during delivery are part of Data Analytics which involves analyzing the raw data to make informed decisions.\\nBut this raw data does not help make decisions if it has some redundancy, inconsistency, or inaccuracy.\\nTherefore, this data needs to be cleaned before considering for analysis.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hRY9s1CNwyCC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PW-VY5avMM-k"
      },
      "outputs": [],
      "source": [
        "# Initiate the Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KKzj7JNzMSSJ"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts([text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V8myerEMVTB",
        "outputId": "ea47e4af-081d-450c-9e00-391e64870b49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRl6t-h0NRNw",
        "outputId": "273d8c81-e0ac-41ab-9f72-8a24f438a4d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data plays a vital role in our everyday life.\n",
            "Directly or indirectly, for daily life decisions, we depend on some data, be it choosing a novel to read from a list of books, buying a thing after considering the budget, and so on.\n",
            "Have you ever imagined searching for something on Google or Yahoo generates a lot of data?\n",
            "This data is essential to analyze user experiences.\n",
            "Getting recommendations on various e-commerce websites after buying a product and tracking parcels during delivery are part of Data Analytics which involves analyzing the raw data to make informed decisions.\n",
            "But this raw data does not help make decisions if it has some redundancy, inconsistency, or inaccuracy.\n",
            "Therefore, this data needs to be cleaned before considering for analysis.\n"
          ]
        }
      ],
      "source": [
        "for sentence in text.split('\\n'):\n",
        "  print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkRWZeniMhH6",
        "outputId": "4178bd03-09fd-426b-ddca-09b6d9b48946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 21, 2, 22, 23, 24, 25, 26, 10]\n",
            "[27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33, 4, 34, 35, 2, 36, 8, 37, 14, 2, 38, 15, 16, 17, 39, 18, 40, 3]\n",
            "[41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49, 2, 50, 8, 1]\n",
            "[9, 1, 51, 52, 4, 53, 54, 55]\n",
            "[56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66, 67, 68, 8, 1, 69, 70, 71, 72, 17, 19, 1, 4, 20, 73, 7]\n",
            "[74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11, 80, 81, 5, 82]\n",
            "[83, 9, 1, 84, 4, 12, 85, 86, 16, 6, 87]\n"
          ]
        }
      ],
      "source": [
        "for sentence in text.split('\\n'):\n",
        "  print(tokenizer.texts_to_sequences([sentence])[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6J5y6cYCMrMB"
      },
      "outputs": [],
      "source": [
        "input_sequences = []\n",
        "\n",
        "for sentence in text.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1, len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yJ1jTKgOJoB",
        "outputId": "e06e6d41-55ed-48b6-b517-695c0e1dc1e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 21],\n",
              " [1, 21, 2],\n",
              " [1, 21, 2, 22],\n",
              " [1, 21, 2, 22, 23],\n",
              " [1, 21, 2, 22, 23, 24],\n",
              " [1, 21, 2, 22, 23, 24, 25],\n",
              " [1, 21, 2, 22, 23, 24, 25, 26],\n",
              " [1, 21, 2, 22, 23, 24, 25, 26, 10],\n",
              " [27, 5],\n",
              " [27, 5, 28],\n",
              " [27, 5, 28, 6],\n",
              " [27, 5, 28, 6, 29],\n",
              " [27, 5, 28, 6, 29, 10],\n",
              " [27, 5, 28, 6, 29, 10, 7],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33, 4],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33, 4, 34],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33, 4, 34, 35],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33, 4, 34, 35, 2],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16,\n",
              "  17],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  39],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  39,\n",
              "  18],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  39,\n",
              "  18,\n",
              "  40],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  39,\n",
              "  18,\n",
              "  40,\n",
              "  3],\n",
              " [41, 42],\n",
              " [41, 42, 43],\n",
              " [41, 42, 43, 44],\n",
              " [41, 42, 43, 44, 45],\n",
              " [41, 42, 43, 44, 45, 6],\n",
              " [41, 42, 43, 44, 45, 6, 46],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49, 2],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49, 2, 50],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49, 2, 50, 8],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49, 2, 50, 8, 1],\n",
              " [9, 1],\n",
              " [9, 1, 51],\n",
              " [9, 1, 51, 52],\n",
              " [9, 1, 51, 52, 4],\n",
              " [9, 1, 51, 52, 4, 53],\n",
              " [9, 1, 51, 52, 4, 53, 54],\n",
              " [9, 1, 51, 52, 4, 53, 54, 55],\n",
              " [56, 57],\n",
              " [56, 57, 3],\n",
              " [56, 57, 3, 58],\n",
              " [56, 57, 3, 58, 59],\n",
              " [56, 57, 3, 58, 59, 60],\n",
              " [56, 57, 3, 58, 59, 60, 61],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66, 67],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66, 67, 68],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66, 67, 68, 8],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66, 67, 68, 8, 1],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19,\n",
              "  1],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19,\n",
              "  1,\n",
              "  4],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19,\n",
              "  1,\n",
              "  4,\n",
              "  20],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19,\n",
              "  1,\n",
              "  4,\n",
              "  20,\n",
              "  73],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19,\n",
              "  1,\n",
              "  4,\n",
              "  20,\n",
              "  73,\n",
              "  7],\n",
              " [74, 9],\n",
              " [74, 9, 19],\n",
              " [74, 9, 19, 1],\n",
              " [74, 9, 19, 1, 75],\n",
              " [74, 9, 19, 1, 75, 76],\n",
              " [74, 9, 19, 1, 75, 76, 77],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11, 80],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11, 80, 81],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11, 80, 81, 5],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11, 80, 81, 5, 82],\n",
              " [83, 9],\n",
              " [83, 9, 1],\n",
              " [83, 9, 1, 84],\n",
              " [83, 9, 1, 84, 4],\n",
              " [83, 9, 1, 84, 4, 12],\n",
              " [83, 9, 1, 84, 4, 12, 85],\n",
              " [83, 9, 1, 84, 4, 12, 85, 86],\n",
              " [83, 9, 1, 84, 4, 12, 85, 86, 16],\n",
              " [83, 9, 1, 84, 4, 12, 85, 86, 16, 6],\n",
              " [83, 9, 1, 84, 4, 12, 85, 86, 16, 6, 87]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8lr5MiQZOQQx"
      },
      "outputs": [],
      "source": [
        "max_len = max([len(x) for x in input_sequences])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKcYzKINUCqt",
        "outputId": "cd8b2bd8-8014-42a3-a0a1-4b40077b715a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "max_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiHVpcl2sQ5a"
      },
      "source": [
        "# Zero Padding for uniform data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vkZZGWTfTeZP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3PvqWMHT7G3",
        "outputId": "5f9705e1-5490-4e43-e682-9fe3c517049f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  1, 21],\n",
              "       [ 0,  0,  0, ...,  1, 21,  2],\n",
              "       [ 0,  0,  0, ..., 21,  2, 22],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 85, 86, 16],\n",
              "       [ 0,  0,  0, ..., 86, 16,  6],\n",
              "       [ 0,  0,  0, ..., 16,  6, 87]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "padded_input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-mXCxNOqUmoW"
      },
      "outputs": [],
      "source": [
        "X = padded_input_sequences[:,:-1]\n",
        "y = padded_input_sequences[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7EX8AUIVLpw",
        "outputId": "c3a25cb9-39fa-4c9a-870f-37156ff6f936"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  0,  1],\n",
              "       [ 0,  0,  0, ...,  0,  1, 21],\n",
              "       [ 0,  0,  0, ...,  1, 21,  2],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 12, 85, 86],\n",
              "       [ 0,  0,  0, ..., 85, 86, 16],\n",
              "       [ 0,  0,  0, ..., 86, 16,  6]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djQ-7TTSVTkQ",
        "outputId": "98558932-c94d-43c8-fe72-f00985f2b82f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([21,  2, 22, 23, 24, 25, 26, 10,  5, 28,  6, 29, 10,  7, 30, 31,  3,\n",
              "       11,  1, 12, 13, 32,  2, 33,  4, 34, 35,  2, 36,  8, 37, 14,  2, 38,\n",
              "       15, 16, 17, 39, 18, 40,  3, 42, 43, 44, 45,  6, 46,  3, 47,  5, 48,\n",
              "       49,  2, 50,  8,  1,  1, 51, 52,  4, 53, 54, 55, 57,  3, 58, 59, 60,\n",
              "       61, 15, 14,  2, 62, 18, 63, 64, 65, 66, 67, 68,  8,  1, 69, 70, 71,\n",
              "       72, 17, 19,  1,  4, 20, 73,  7,  9, 19,  1, 75, 76, 77, 20,  7, 78,\n",
              "       13, 79, 11, 80, 81,  5, 82,  9,  1, 84,  4, 12, 85, 86, 16,  6, 87],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTseIyqMfkYd",
        "outputId": "3fc1162a-e52b-4b20-c8a9-c539eb72d9ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': 1,\n",
              " 'a': 2,\n",
              " 'on': 3,\n",
              " 'to': 4,\n",
              " 'or': 5,\n",
              " 'for': 6,\n",
              " 'decisions': 7,\n",
              " 'of': 8,\n",
              " 'this': 9,\n",
              " 'life': 10,\n",
              " 'some': 11,\n",
              " 'be': 12,\n",
              " 'it': 13,\n",
              " 'buying': 14,\n",
              " 'after': 15,\n",
              " 'considering': 16,\n",
              " 'the': 17,\n",
              " 'and': 18,\n",
              " 'raw': 19,\n",
              " 'make': 20,\n",
              " 'plays': 21,\n",
              " 'vital': 22,\n",
              " 'role': 23,\n",
              " 'in': 24,\n",
              " 'our': 25,\n",
              " 'everyday': 26,\n",
              " 'directly': 27,\n",
              " 'indirectly': 28,\n",
              " 'daily': 29,\n",
              " 'we': 30,\n",
              " 'depend': 31,\n",
              " 'choosing': 32,\n",
              " 'novel': 33,\n",
              " 'read': 34,\n",
              " 'from': 35,\n",
              " 'list': 36,\n",
              " 'books': 37,\n",
              " 'thing': 38,\n",
              " 'budget': 39,\n",
              " 'so': 40,\n",
              " 'have': 41,\n",
              " 'you': 42,\n",
              " 'ever': 43,\n",
              " 'imagined': 44,\n",
              " 'searching': 45,\n",
              " 'something': 46,\n",
              " 'google': 47,\n",
              " 'yahoo': 48,\n",
              " 'generates': 49,\n",
              " 'lot': 50,\n",
              " 'is': 51,\n",
              " 'essential': 52,\n",
              " 'analyze': 53,\n",
              " 'user': 54,\n",
              " 'experiences': 55,\n",
              " 'getting': 56,\n",
              " 'recommendations': 57,\n",
              " 'various': 58,\n",
              " 'e': 59,\n",
              " 'commerce': 60,\n",
              " 'websites': 61,\n",
              " 'product': 62,\n",
              " 'tracking': 63,\n",
              " 'parcels': 64,\n",
              " 'during': 65,\n",
              " 'delivery': 66,\n",
              " 'are': 67,\n",
              " 'part': 68,\n",
              " 'analytics': 69,\n",
              " 'which': 70,\n",
              " 'involves': 71,\n",
              " 'analyzing': 72,\n",
              " 'informed': 73,\n",
              " 'but': 74,\n",
              " 'does': 75,\n",
              " 'not': 76,\n",
              " 'help': 77,\n",
              " 'if': 78,\n",
              " 'has': 79,\n",
              " 'redundancy': 80,\n",
              " 'inconsistency': 81,\n",
              " 'inaccuracy': 82,\n",
              " 'therefore': 83,\n",
              " 'needs': 84,\n",
              " 'cleaned': 85,\n",
              " 'before': 86,\n",
              " 'analysis': 87}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqoYW-3EsQ5e"
      },
      "source": [
        "# Since this is a classification problem and not regression. So we need to encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BikWaC4fg0y1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, num_classes=88)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62RBz7AwhCe0",
        "outputId": "732c050b-d8b3-46b5-f6b3-851712ea66f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 88)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vns3pQFNhSFq",
        "outputId": "68ec939b-8cf3-4ce8-dd32-4da21ac9d997"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyFeZ9R1FPzH"
      },
      "source": [
        "### **Model Building**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3JGGM9PlhTqK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lIbSgCVHFbO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43c6236f-bdc4-4235-f902-477cd87fd783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(88,100,input_length=33))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(88,activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLS2E9qmsQ5f"
      },
      "source": [
        "## model.add(LSTM(150))=> This means 150 nodes. So dimensions would be 150X1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bDG251CFFgHX"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "_JgOuNxiGPgH",
        "outputId": "7d63225b-f214-4ae8-80b7-380a0b989e11"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWHNq7UQIW6T",
        "outputId": "ce9a4275-7dd2-4bee-aa6d-27f515b72689"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agZhL4gCMRgx",
        "outputId": "36f943d8-07be-42e7-d8ed-edfe695bc993"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 88)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpx97gBhMS2y",
        "outputId": "7583a872-a130-4a9f-ab13-78256708455d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.0034 - loss: 4.4782    \n",
            "Epoch 2/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.0922 - loss: 4.4594\n",
            "Epoch 3/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.0795 - loss: 4.4253\n",
            "Epoch 4/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.0550 - loss: 4.3326\n",
            "Epoch 5/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.0610 - loss: 4.2693\n",
            "Epoch 6/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.0688 - loss: 4.2654\n",
            "Epoch 7/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.0613 - loss: 4.2414\n",
            "Epoch 8/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.0527 - loss: 4.1612\n",
            "Epoch 9/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.0727 - loss: 4.0829\n",
            "Epoch 10/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.0633 - loss: 4.0388\n",
            "Epoch 11/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.0524 - loss: 3.9720\n",
            "Epoch 12/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.0852 - loss: 3.8268\n",
            "Epoch 13/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.1055 - loss: 3.7634\n",
            "Epoch 14/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.1008 - loss: 3.7395\n",
            "Epoch 15/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.0976 - loss: 3.6372\n",
            "Epoch 16/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.0955 - loss: 3.6066\n",
            "Epoch 17/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1189 - loss: 3.4970\n",
            "Epoch 18/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.1275 - loss: 3.4293\n",
            "Epoch 19/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.0864 - loss: 3.3868\n",
            "Epoch 20/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.1012 - loss: 3.2877\n",
            "Epoch 21/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1712 - loss: 3.2050\n",
            "Epoch 22/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2118 - loss: 3.1095\n",
            "Epoch 23/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.1570 - loss: 3.0577\n",
            "Epoch 24/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.2416 - loss: 2.9778\n",
            "Epoch 25/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2642 - loss: 2.8117\n",
            "Epoch 26/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.2661 - loss: 2.8604\n",
            "Epoch 27/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.2644 - loss: 2.7145\n",
            "Epoch 28/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.2935 - loss: 2.6512\n",
            "Epoch 29/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.3605 - loss: 2.5858\n",
            "Epoch 30/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.3121 - loss: 2.5114\n",
            "Epoch 31/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4299 - loss: 2.4241\n",
            "Epoch 32/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3742 - loss: 2.4290\n",
            "Epoch 33/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.4020 - loss: 2.3307\n",
            "Epoch 34/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4340 - loss: 2.2324\n",
            "Epoch 35/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5161 - loss: 2.1015\n",
            "Epoch 36/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5278 - loss: 2.0444\n",
            "Epoch 37/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5449 - loss: 2.0292\n",
            "Epoch 38/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6165 - loss: 1.9091\n",
            "Epoch 39/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6337 - loss: 1.8654\n",
            "Epoch 40/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6482 - loss: 1.8381\n",
            "Epoch 41/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6894 - loss: 1.7501\n",
            "Epoch 42/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6513 - loss: 1.7359\n",
            "Epoch 43/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6271 - loss: 1.6697\n",
            "Epoch 44/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6453 - loss: 1.6300\n",
            "Epoch 45/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7094 - loss: 1.5711\n",
            "Epoch 46/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6977 - loss: 1.5342\n",
            "Epoch 47/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6930 - loss: 1.4962\n",
            "Epoch 48/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7986 - loss: 1.4224\n",
            "Epoch 49/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8261 - loss: 1.3414\n",
            "Epoch 50/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8372 - loss: 1.3504\n",
            "Epoch 51/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8858 - loss: 1.3035\n",
            "Epoch 52/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8910 - loss: 1.2386\n",
            "Epoch 53/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9174 - loss: 1.2180\n",
            "Epoch 54/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8579 - loss: 1.2296\n",
            "Epoch 55/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9055 - loss: 1.1836\n",
            "Epoch 56/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9047 - loss: 1.1898\n",
            "Epoch 57/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9387 - loss: 1.1300\n",
            "Epoch 58/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9341 - loss: 1.0604\n",
            "Epoch 59/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9322 - loss: 1.0332\n",
            "Epoch 60/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9291 - loss: 1.0466\n",
            "Epoch 61/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9078 - loss: 1.0325\n",
            "Epoch 62/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9013 - loss: 1.0447\n",
            "Epoch 63/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9463 - loss: 0.9872\n",
            "Epoch 64/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9530 - loss: 0.9577\n",
            "Epoch 65/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9657 - loss: 0.9025\n",
            "Epoch 66/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9899 - loss: 0.8884\n",
            "Epoch 67/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.9743 - loss: 0.8612\n",
            "Epoch 68/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9732 - loss: 0.8723\n",
            "Epoch 69/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.9647 - loss: 0.8316\n",
            "Epoch 70/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9946 - loss: 0.7796\n",
            "Epoch 71/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9966 - loss: 0.7875\n",
            "Epoch 72/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9914 - loss: 0.7486\n",
            "Epoch 73/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9914 - loss: 0.7227\n",
            "Epoch 74/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9914 - loss: 0.6921\n",
            "Epoch 75/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9914 - loss: 0.6854\n",
            "Epoch 76/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9852 - loss: 0.7021\n",
            "Epoch 77/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9891 - loss: 0.6539\n",
            "Epoch 78/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9766 - loss: 0.6440\n",
            "Epoch 79/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9797 - loss: 0.6007\n",
            "Epoch 80/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9946 - loss: 0.6134\n",
            "Epoch 81/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9852 - loss: 0.5788\n",
            "Epoch 82/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9818 - loss: 0.5697\n",
            "Epoch 83/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9933 - loss: 0.5604\n",
            "Epoch 84/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9966 - loss: 0.5266\n",
            "Epoch 85/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9914 - loss: 0.5361\n",
            "Epoch 86/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9946 - loss: 0.5073\n",
            "Epoch 87/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9914 - loss: 0.5092\n",
            "Epoch 88/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9966 - loss: 0.4789\n",
            "Epoch 89/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9946 - loss: 0.4633\n",
            "Epoch 90/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9946 - loss: 0.4618\n",
            "Epoch 91/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9852 - loss: 0.4711\n",
            "Epoch 92/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9946 - loss: 0.4309\n",
            "Epoch 93/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9914 - loss: 0.4302\n",
            "Epoch 94/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9914 - loss: 0.4434\n",
            "Epoch 95/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9852 - loss: 0.4215\n",
            "Epoch 96/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9946 - loss: 0.4025\n",
            "Epoch 97/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9966 - loss: 0.4063\n",
            "Epoch 98/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9852 - loss: 0.3835\n",
            "Epoch 99/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9852 - loss: 0.3818\n",
            "Epoch 100/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9914 - loss: 0.3607\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e4b51f2f210>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "model.fit(X,y,epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQPjc7WqMqxB"
      },
      "source": [
        "#### **Test the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MUI7BxvMW-J",
        "outputId": "86209657-eebc-45aa-bd2a-913ba4bb7927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.99350283e-05, 1.05470521e-02, 1.08193923e-02, 2.31505348e-03,\n",
              "        2.12406390e-03, 1.15899090e-02, 5.03256405e-03, 5.36279731e-05,\n",
              "        2.14405751e-04, 9.81052518e-02, 8.25280513e-05, 2.39270503e-05,\n",
              "        3.27085494e-03, 7.82370262e-05, 8.39188651e-05, 3.46236666e-05,\n",
              "        2.76352279e-04, 7.27597362e-05, 6.55285839e-05, 7.24196993e-03,\n",
              "        2.11883889e-04, 6.22474670e-01, 4.00825590e-03, 1.33341854e-03,\n",
              "        8.70304473e-04, 3.21527827e-04, 1.53978908e-04, 2.37743807e-05,\n",
              "        4.72352607e-03, 6.36460900e-04, 1.44636404e-04, 6.03020490e-05,\n",
              "        1.45484024e-04, 6.46055632e-05, 4.94307496e-05, 1.04381666e-04,\n",
              "        1.16434667e-05, 8.08096593e-05, 8.80284497e-05, 1.45652826e-04,\n",
              "        7.95012602e-06, 2.87989551e-05, 6.36245217e-03, 6.39781822e-03,\n",
              "        1.78222777e-03, 2.99228937e-04, 1.10665205e-04, 1.27454958e-04,\n",
              "        3.45684020e-05, 1.33114110e-04, 1.49696323e-04, 1.03713378e-01,\n",
              "        5.42739965e-03, 6.81088073e-04, 1.57447110e-04, 4.62238968e-05,\n",
              "        2.48005053e-05, 1.99595075e-02, 1.44338293e-03, 2.86466704e-04,\n",
              "        1.65237157e-04, 3.54354161e-05, 3.01306591e-05, 1.98712878e-05,\n",
              "        2.08862693e-05, 1.01634696e-05, 1.02001650e-05, 2.28863737e-05,\n",
              "        2.03517393e-05, 5.68308897e-05, 8.30729114e-05, 1.69285064e-04,\n",
              "        1.70736486e-04, 3.45911903e-05, 2.61576079e-05, 1.19863264e-02,\n",
              "        1.69632770e-03, 8.00315931e-04, 7.53233835e-05, 8.78001520e-05,\n",
              "        4.80095878e-05, 4.81442476e-05, 9.06483256e-05, 1.54114132e-05,\n",
              "        4.88817804e-02, 1.74044035e-04, 2.32090926e-04, 8.96344645e-05]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "text2 = \"Data\"\n",
        "\n",
        "# tokenization\n",
        "token_text = tokenizer.texts_to_sequences([text2])[0]\n",
        "# padding\n",
        "padded_text = pad_sequences([token_text], maxlen=33, padding='pre')\n",
        "# model prediction\n",
        "model.predict(padded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJLGl4HSNjE0",
        "outputId": "cdbafac3-bfbc-4b3d-905b-ed28d3bcfda1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(21)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "import numpy as np\n",
        "pos = np.argmax(model.predict(padded_text))\n",
        "pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBUE1sHnNEO6",
        "outputId": "55ad49f1-550c-4526-cf7b-60df992acbbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': 1,\n",
              " 'a': 2,\n",
              " 'on': 3,\n",
              " 'to': 4,\n",
              " 'or': 5,\n",
              " 'for': 6,\n",
              " 'decisions': 7,\n",
              " 'of': 8,\n",
              " 'this': 9,\n",
              " 'life': 10,\n",
              " 'some': 11,\n",
              " 'be': 12,\n",
              " 'it': 13,\n",
              " 'buying': 14,\n",
              " 'after': 15,\n",
              " 'considering': 16,\n",
              " 'the': 17,\n",
              " 'and': 18,\n",
              " 'raw': 19,\n",
              " 'make': 20,\n",
              " 'plays': 21,\n",
              " 'vital': 22,\n",
              " 'role': 23,\n",
              " 'in': 24,\n",
              " 'our': 25,\n",
              " 'everyday': 26,\n",
              " 'directly': 27,\n",
              " 'indirectly': 28,\n",
              " 'daily': 29,\n",
              " 'we': 30,\n",
              " 'depend': 31,\n",
              " 'choosing': 32,\n",
              " 'novel': 33,\n",
              " 'read': 34,\n",
              " 'from': 35,\n",
              " 'list': 36,\n",
              " 'books': 37,\n",
              " 'thing': 38,\n",
              " 'budget': 39,\n",
              " 'so': 40,\n",
              " 'have': 41,\n",
              " 'you': 42,\n",
              " 'ever': 43,\n",
              " 'imagined': 44,\n",
              " 'searching': 45,\n",
              " 'something': 46,\n",
              " 'google': 47,\n",
              " 'yahoo': 48,\n",
              " 'generates': 49,\n",
              " 'lot': 50,\n",
              " 'is': 51,\n",
              " 'essential': 52,\n",
              " 'analyze': 53,\n",
              " 'user': 54,\n",
              " 'experiences': 55,\n",
              " 'getting': 56,\n",
              " 'recommendations': 57,\n",
              " 'various': 58,\n",
              " 'e': 59,\n",
              " 'commerce': 60,\n",
              " 'websites': 61,\n",
              " 'product': 62,\n",
              " 'tracking': 63,\n",
              " 'parcels': 64,\n",
              " 'during': 65,\n",
              " 'delivery': 66,\n",
              " 'are': 67,\n",
              " 'part': 68,\n",
              " 'analytics': 69,\n",
              " 'which': 70,\n",
              " 'involves': 71,\n",
              " 'analyzing': 72,\n",
              " 'informed': 73,\n",
              " 'but': 74,\n",
              " 'does': 75,\n",
              " 'not': 76,\n",
              " 'help': 77,\n",
              " 'if': 78,\n",
              " 'has': 79,\n",
              " 'redundancy': 80,\n",
              " 'inconsistency': 81,\n",
              " 'inaccuracy': 82,\n",
              " 'therefore': 83,\n",
              " 'needs': 84,\n",
              " 'cleaned': 85,\n",
              " 'before': 86,\n",
              " 'analysis': 87}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emawpNAINzRC",
        "outputId": "02670ea3-0ebb-4fcd-a107-037c74106ea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "plays\n"
          ]
        }
      ],
      "source": [
        "for word, index in tokenizer.word_index.items():\n",
        "  if index==pos:\n",
        "    print(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbbZiNtGOKjZ",
        "outputId": "c47cb8a7-e8e4-4dcf-ed0a-df40769bc836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "in\n"
          ]
        }
      ],
      "source": [
        "text3 = \"Data plays a vital role\"\n",
        "\n",
        "# tokenization\n",
        "token_text3 = tokenizer.texts_to_sequences([text3])[0]\n",
        "# padding\n",
        "padded_text3 = pad_sequences([token_text3], maxlen=33, padding='pre')\n",
        "# model prediction\n",
        "model.predict(padded_text3)\n",
        "\n",
        "pos3 = np.argmax(model.predict(padded_text3))\n",
        "\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  if index==pos3:\n",
        "    print(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYdZ-2gtOiHp",
        "outputId": "b85c87e7-82fc-423b-9d84-289929ae150a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "life\n"
          ]
        }
      ],
      "source": [
        "text3 = \"Data is a vital role in our everyday life\"\n",
        "\n",
        "# tokenization\n",
        "token_text3 = tokenizer.texts_to_sequences([text3])[0]\n",
        "# padding\n",
        "padded_text3 = pad_sequences([token_text3], maxlen=33, padding='pre')\n",
        "# model prediction\n",
        "model.predict(padded_text3)\n",
        "\n",
        "pos3 = np.argmax(model.predict(padded_text3))\n",
        "\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  if index==pos3:\n",
        "    print(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Savwt9c9O1Yx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}