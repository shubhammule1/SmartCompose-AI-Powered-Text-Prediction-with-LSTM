# SmartCompose-AI-Powered-Text-Prediction-with-LSTM
SmartCompose: AI-Powered Text Prediction with LSTM
ðŸ“Œ Overview

This project implements a Smart Compose feature using Long Short-Term Memory (LSTM) networks. The model predicts and suggests the next word or phrase based on user input, similar to predictive text features found in applications like Gmail and messaging apps.

ðŸš€ Features

Text Completion: Predicts and suggests words/phrases based on context.

Deep Learning Model: Uses LSTM, a type of Recurrent Neural Network (RNN), to handle sequential data.

Personalization: Can be fine-tuned on domain-specific datasets.

âœ¨Implementation Details

This project utilizes TensorFlow and Keras to train an LSTM-based model for text prediction. Below are the key steps:

Tokenization:

Uses Tokenizer from tensorflow.keras.preprocessing.text to tokenize text input.

Converts sentences into sequences of integers based on word index.

Sequence Preparation:

Splits sentences into input sequences for training.

Uses pad_sequences to ensure uniform input size.

Model Architecture:

Embedding Layer: Randomly initialized embedding layer for learning word representations.

LSTM Layer: Learns sequential dependencies in text.

Dense Layer: Uses a softmax activation function for word prediction.

Training:

Uses categorical_crossentropy loss function.

Optimized using Adam optimizer.

Trained for 100 epochs.
